{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36197509-9db1-4251-b618-105950b94b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Начало процесса Загрузка FT_POSTING_F в 2025-04-22 09:32:22.565309\n",
      "INFO:__main__:Данные сохранены в data/parquet/FT_POSTING_F\n",
      "INFO:__main__:Завершение процесса Загрузка FT_POSTING_F, статус: completed, продолжительность: 16.98 сек.\n",
      "INFO:__main__:Начало процесса Загрузка FT_BALANCE_F в 2025-04-22 09:32:39.544506\n",
      "INFO:__main__:Данные сохранены в data/parquet/FT_BALANCE_F\n",
      "INFO:__main__:Завершение процесса Загрузка FT_BALANCE_F, статус: completed, продолжительность: 6.17 сек.\n",
      "INFO:__main__:Начало процесса Загрузка MD_ACCOUNT_D в 2025-04-22 09:32:45.715924\n",
      "INFO:__main__:Таблица Загрузка MD_ACCOUNT_D не существует, будет создана новая\n",
      "INFO:__main__:Данные сохранены в data/parquet/MD_ACCOUNT_D\n",
      "INFO:__main__:Завершение процесса Загрузка MD_ACCOUNT_D, статус: completed, продолжительность: 6.34 сек.\n",
      "INFO:__main__:Начало процесса Загрузка MD_CURRENCY_D в 2025-04-22 09:32:52.059622\n",
      "INFO:__main__:Таблица Загрузка MD_CURRENCY_D не существует, будет создана новая\n",
      "INFO:__main__:Данные сохранены в data/parquet/MD_CURRENCY_D\n",
      "INFO:__main__:Завершение процесса Загрузка MD_CURRENCY_D, статус: completed, продолжительность: 5.91 сек.\n",
      "INFO:__main__:Начало процесса Загрузка MD_EXCHANGE_RATE_D в 2025-04-22 09:32:57.973780\n",
      "INFO:__main__:Таблица Загрузка MD_EXCHANGE_RATE_D не существует, будет создана новая\n",
      "INFO:__main__:Данные сохранены в data/parquet/MD_EXCHANGE_RATE_D\n",
      "INFO:__main__:Завершение процесса Загрузка MD_EXCHANGE_RATE_D, статус: completed, продолжительность: 5.84 сек.\n",
      "INFO:__main__:Начало процесса Загрузка MD_LEDGER_ACCOUNT_S в 2025-04-22 09:33:03.817635\n",
      "INFO:__main__:Таблица Загрузка MD_LEDGER_ACCOUNT_S не существует, будет создана новая\n",
      "INFO:__main__:Данные сохранены в data/parquet/MD_LEDGER_ACCOUNT_S\n",
      "INFO:__main__:Завершение процесса Загрузка MD_LEDGER_ACCOUNT_S, статус: completed, продолжительность: 5.80 сек.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DateType, IntegerType, StringType, FloatType\n",
    "from pyspark.sql.functions import udf, lit, coalesce, current_date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SparkETLProcessor:\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"BankDataETL\") \\\n",
    "            .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        # Определение схем\n",
    "        self.schema_md_account_d = StructType([\n",
    "            StructField(\"data_actual_date\", DateType(), nullable=False),\n",
    "            StructField(\"data_actual_end_date\", DateType(), nullable=False),\n",
    "            StructField(\"account_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"account_number\", StringType(), nullable=False),\n",
    "            StructField(\"char_type\", StringType(), nullable=False),\n",
    "            StructField(\"currency_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"currency_code\", StringType(), nullable=False)\n",
    "        ])\n",
    "        \n",
    "        self.schema_md_currency_d = StructType([\n",
    "            StructField(\"currency_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"data_actual_date\", DateType(), nullable=False),\n",
    "            StructField(\"data_actual_end_date\", DateType()),\n",
    "            StructField(\"currency_code\", StringType()),\n",
    "            StructField(\"code_iso_char\", StringType())\n",
    "        ])\n",
    "        \n",
    "        self.schema_ft_posting_f = StructType([\n",
    "            StructField(\"oper_date\", DateType(), nullable=False),\n",
    "            StructField(\"credit_account_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"debet_account_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"credit_amount\", FloatType()),\n",
    "            StructField(\"debet_amount\", FloatType())\n",
    "        ])\n",
    "        \n",
    "        self.schema_ft_balance_f = StructType([\n",
    "            StructField(\"on_date\", DateType(), nullable=False),\n",
    "            StructField(\"account_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"currency_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"balance_out\", FloatType(), nullable=False)\n",
    "        ])\n",
    "        \n",
    "        self.schema_md_exchange_rate_d = StructType([\n",
    "            StructField(\"data_actual_date\", DateType(), nullable=False),\n",
    "            StructField(\"currency_rk\", IntegerType(), nullable=False),\n",
    "            StructField(\"reduced_rate\", FloatType()),\n",
    "            StructField(\"code_iso_num\", StringType())\n",
    "        ])\n",
    "        \n",
    "        self.schema_md_ledger_account_s = StructType([\n",
    "            StructField(\"ledger_account\", StringType(), nullable=False),\n",
    "            StructField(\"start_date\", DateType(), nullable=False),\n",
    "            StructField(\"end_date\", DateType()),\n",
    "            StructField(\"chapter\", StringType()),\n",
    "            StructField(\"account_name\", StringType())\n",
    "        ])\n",
    "\n",
    "    def log_process_start(self, process_name):\n",
    "        \"\"\"Логирование начала процесса\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        logger.info(f\"Начало процесса {process_name} в {start_time}\")\n",
    "        return start_time\n",
    "\n",
    "    def log_process_end(self, start_time, process_name, status, rows_processed=None, error_message=None):\n",
    "        \"\"\"Логирование завершения процесса\"\"\"\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        logger.info(f\"Завершение процесса {process_name}, статус: {status}, продолжительность: {duration:.2f} сек.\")\n",
    "\n",
    "    def parse_date(self, date_str):\n",
    "        \"\"\"Функция для парсинга дат в UDF\"\"\"\n",
    "        from dateutil.parser import parse\n",
    "        try:\n",
    "            return parse(date_str).date()\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def load_csv_with_schema(self, file_path, schema, date_columns=None):\n",
    "        \"\"\"Загрузка CSV с применением схемы\"\"\"\n",
    "        try:\n",
    "            # Регистрируем UDF для парсинга дат\n",
    "            parse_date_udf = udf(self.parse_date, DateType())\n",
    "            \n",
    "            # Читаем CSV с inferSchema, затем применяем нашу схему\n",
    "            df = self.spark.read.option(\"header\", \"true\").option(\"sep\", \";\").option(\"inferSchema\", \"true\").csv(file_path)\n",
    "            \n",
    "            # Приводим типы данных к целевой схеме\n",
    "            for field in schema.fields:\n",
    "                col_name = field.name\n",
    "                if col_name in df.columns:\n",
    "                    if isinstance(field.dataType, DateType):\n",
    "                        df = df.withColumn(col_name, parse_date_udf(df[col_name]))\n",
    "                    elif str(df.schema[col_name].dataType) != str(field.dataType):\n",
    "                        df = df.withColumn(col_name, df[col_name].cast(field.dataType))\n",
    "            \n",
    "            # Применяем схему (проверяем обязательные поля)\n",
    "            for field in schema.fields:\n",
    "                if field.nullable == False:\n",
    "                    df = df.filter(df[field.name].isNotNull())\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка загрузки CSV {file_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def save_as_parquet(self, df, output_path, partition_cols=None, mode=\"overwrite\"):\n",
    "        \"\"\"Сохранение DataFrame в Parquet\"\"\"\n",
    "        try:\n",
    "            writer = df.write.mode(mode)\n",
    "            if partition_cols:\n",
    "                writer = writer.partitionBy(partition_cols)\n",
    "            writer.parquet(output_path)\n",
    "            logger.info(f\"Данные сохранены в {output_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка сохранения Parquet: {e}\")\n",
    "            raise\n",
    "\n",
    "    def update_dimension_table(self, new_data_df, table_name, output_path, primary_keys):\n",
    "        \"\"\"Общая стратегия обновления для таблиц измерений\"\"\"\n",
    "        try:\n",
    "            # Проверяем существование таблицы\n",
    "            existing_df = None\n",
    "            try:\n",
    "                existing_df = self.spark.read.parquet(output_path)\n",
    "                logger.info(f\"Обнаружена существующая таблица {table_name}\")\n",
    "            except:\n",
    "                logger.info(f\"Таблица {table_name} не существует, будет создана новая\")\n",
    "                existing_df = None\n",
    "            \n",
    "            if existing_df is None:\n",
    "                # Если таблицы нет, просто сохраняем новые данные\n",
    "                self.save_as_parquet(new_data_df, output_path)\n",
    "                return new_data_df.count()\n",
    "            \n",
    "            # Определяем ключи для join\n",
    "            join_condition = None\n",
    "            for key in primary_keys:\n",
    "                if join_condition is None:\n",
    "                    join_condition = (new_data_df[key] == existing_df[key])\n",
    "                else:\n",
    "                    join_condition = join_condition & (new_data_df[key] == existing_df[key])\n",
    "            \n",
    "            # Находим записи для обновления (существующие записи)\n",
    "            updates_df = new_data_df.join(existing_df, join_condition, \"inner\")\n",
    "            \n",
    "            if updates_df.count() > 0:\n",
    "                # Обновляем data_actual_end_date для старых записей\n",
    "                old_records_to_update = existing_df.join(\n",
    "                    new_data_df.select(primary_keys[0]), \n",
    "                    primary_keys[0], \n",
    "                    \"inner\"\n",
    "                )\n",
    "                \n",
    "                old_records_updated = old_records_to_update.withColumn(\n",
    "                    \"data_actual_end_date\", \n",
    "                    current_date()\n",
    "                )\n",
    "                \n",
    "                # Оставляем старые записи, которые не обновляются\n",
    "                old_records_unchanged = existing_df.join(\n",
    "                    new_data_df.select(primary_keys[0]), \n",
    "                    primary_keys[0], \n",
    "                    \"left_anti\"\n",
    "                )\n",
    "                \n",
    "                # Объединяем все данные\n",
    "                final_df = old_records_unchanged.unionByName(old_records_updated).unionByName(new_data_df)\n",
    "            else:\n",
    "                # Если нет обновлений, просто добавляем новые записи\n",
    "                final_df = existing_df.unionByName(new_data_df)\n",
    "            \n",
    "            # Сохраняем результат\n",
    "            self.save_as_parquet(final_df, output_path)\n",
    "            return final_df.count()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка обновления таблицы {table_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def process_table(self, file_path, schema, output_path, process_name, table_type, primary_keys=None):\n",
    "        \"\"\"Основной метод обработки таблицы с учетом типа таблицы\"\"\"\n",
    "        start_time = None\n",
    "        try:\n",
    "            # Логируем начало процесса\n",
    "            start_time = self.log_process_start(process_name)\n",
    "\n",
    "            # Искусственная пауза для демонстрации\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # Загружаем данные с применением схемы\n",
    "            df = self.load_csv_with_schema(file_path, schema)\n",
    "            \n",
    "            # Применяем соответствующую стратегию обновления\n",
    "            if table_type == \"FACT\" and \"FT_POSTING_F\" in output_path:\n",
    "                # Для FT_POSTING_F - полная перезагрузка\n",
    "                self.save_as_parquet(df, output_path, mode=\"overwrite\")\n",
    "                rows_processed = df.count()\n",
    "            elif table_type == \"FACT\":\n",
    "                # Для других фактов - обновление по ключам\n",
    "                if not primary_keys:\n",
    "                    raise ValueError(f\"Для таблицы фактов {output_path} необходимо указать первичные ключи\")\n",
    "                \n",
    "                # Проверяем существование таблицы\n",
    "                try:\n",
    "                    existing_df = self.spark.read.parquet(output_path)\n",
    "                    \n",
    "                    # Удаляем старые записи, которые будут обновлены\n",
    "                    existing_df = existing_df.join(\n",
    "                        df.select(primary_keys), \n",
    "                        primary_keys, \n",
    "                        \"left_anti\"\n",
    "                    )\n",
    "                    \n",
    "                    # Объединяем старые и новые записи\n",
    "                    final_df = existing_df.unionByName(df)\n",
    "                    self.save_as_parquet(final_df, output_path)\n",
    "                    rows_processed = final_df.count()\n",
    "                except:\n",
    "                    # Если таблицы нет, просто сохраняем\n",
    "                    self.save_as_parquet(df, output_path)\n",
    "                    rows_processed = df.count()\n",
    "            elif table_type == \"DIMENSION\":\n",
    "                # Для измерений - сложное обновление с историей\n",
    "                if not primary_keys:\n",
    "                    raise ValueError(f\"Для таблицы измерения {output_path} необходимо указать первичные ключи\")\n",
    "                rows_processed = self.update_dimension_table(df, process_name, output_path, primary_keys)\n",
    "            else:\n",
    "                raise ValueError(f\"Неизвестный тип таблицы: {table_type}\")\n",
    "            \n",
    "            # Логируем успешное завершение\n",
    "            self.log_process_end(\n",
    "                start_time, \n",
    "                process_name, \n",
    "                'completed', \n",
    "                rows_processed=rows_processed\n",
    "            )\n",
    "            \n",
    "            return rows_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Логируем ошибку\n",
    "            if start_time:\n",
    "                self.log_process_end(\n",
    "                    start_time, \n",
    "                    process_name, \n",
    "                    'failed', \n",
    "                    error_message=str(e)\n",
    "                )\n",
    "            logger.error(f\"Ошибка обработки: {e}\")\n",
    "            raise\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    etl = None\n",
    "    try:\n",
    "        etl = SparkETLProcessor()\n",
    "        \n",
    "        # Обработка таблиц с соответствующими стратегиями обновления\n",
    "        \n",
    "        # 1. FT_POSTING_F - полная перезагрузка\n",
    "        etl.process_table(\n",
    "            file_path=\"data/ft_posting_f.csv\",\n",
    "            schema=etl.schema_ft_posting_f,\n",
    "            output_path=\"data/parquet/FT_POSTING_F\",\n",
    "            process_name=\"Загрузка FT_POSTING_F\",\n",
    "            table_type=\"FACT\"\n",
    "        )\n",
    "        \n",
    "        # 2. FT_BALANCE_F - обновление по ключу (ON_DATE, ACCOUNT_RK)\n",
    "        etl.process_table(\n",
    "            file_path=\"data/ft_balance_f.csv\",\n",
    "            schema=etl.schema_ft_balance_f,\n",
    "            output_path=\"data/parquet/FT_BALANCE_F\",\n",
    "            process_name=\"Загрузка FT_BALANCE_F\",\n",
    "            table_type=\"FACT\",\n",
    "            primary_keys=[\"on_date\", \"account_rk\"]\n",
    "        )\n",
    "        \n",
    "        # 3. MD_ACCOUNT_D - обновление измерения (DATA_ACTUAL_DATE, ACCOUNT_RK)\n",
    "        etl.process_table(\n",
    "            file_path=\"data/md_account_d.csv\",\n",
    "            schema=etl.schema_md_account_d,\n",
    "            output_path=\"data/parquet/MD_ACCOUNT_D\",\n",
    "            process_name=\"Загрузка MD_ACCOUNT_D\",\n",
    "            table_type=\"DIMENSION\",\n",
    "            primary_keys=[\"data_actual_date\", \"account_rk\"]\n",
    "        )\n",
    "        \n",
    "        # 4. MD_CURRENCY_D - обновление измерения (CURRENCY_RK, DATA_ACTUAL_DATE)\n",
    "        etl.process_table(\n",
    "            file_path=\"data/md_currency_d.csv\",\n",
    "            schema=etl.schema_md_currency_d,\n",
    "            output_path=\"data/parquet/MD_CURRENCY_D\",\n",
    "            process_name=\"Загрузка MD_CURRENCY_D\",\n",
    "            table_type=\"DIMENSION\",\n",
    "            primary_keys=[\"data_actual_date\",\"currency_rk\"] \n",
    "        )\n",
    "\n",
    "        # 5. MD_EXCHANGE_RATE_D - обновление измерения (DATA_ACTUAL_DATE, CURRENCY_RK)\n",
    "        etl.process_table(\n",
    "            file_path=\"data/md_exchange_rate_d.csv\",\n",
    "            schema=etl.schema_md_exchange_rate_d,\n",
    "            output_path=\"data/parquet/MD_EXCHANGE_RATE_D\",\n",
    "            process_name=\"Загрузка MD_EXCHANGE_RATE_D\",\n",
    "            table_type=\"DIMENSION\",\n",
    "            primary_keys=[\"data_actual_date\", \"currency_rk\"]\n",
    "        )\n",
    "        \n",
    "        # 6. MD_LEDGER_ACCOUNT_S - обновление измерения (LEDGER_ACCOUNT, START_DATE)\n",
    "        etl.process_table(\n",
    "            file_path=\"data/md_ledger_account_s.csv\",\n",
    "            schema=etl.schema_md_ledger_account_s,\n",
    "            output_path=\"data/parquet/MD_LEDGER_ACCOUNT_S\",\n",
    "            process_name=\"Загрузка MD_LEDGER_ACCOUNT_S\",\n",
    "            table_type=\"DIMENSION\",\n",
    "            primary_keys=[\"ledger_account\", \"start_date\"]\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка в основном процессе: {e}\")\n",
    "    finally:\n",
    "        if etl is not None:\n",
    "            etl.spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2983cd10-dd37-4bb1-af3e-d7bb128c33bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FT_BALANCE_F ===\n",
      "-RECORD 0-----------------\n",
      " ON_DATE     | 31.12.2017 \n",
      " ACCOUNT_RK  | 36237725   \n",
      " CURRENCY_RK | 35         \n",
      " BALANCE_OUT | 38318.13   \n",
      "-RECORD 1-----------------\n",
      " ON_DATE     | 31.12.2017 \n",
      " ACCOUNT_RK  | 24656      \n",
      " CURRENCY_RK | 35         \n",
      " BALANCE_OUT | 80533.62   \n",
      "-RECORD 2-----------------\n",
      " ON_DATE     | 31.12.2017 \n",
      " ACCOUNT_RK  | 18849846   \n",
      " CURRENCY_RK | 34         \n",
      " BALANCE_OUT | 63891.96   \n",
      "-RECORD 3-----------------\n",
      " ON_DATE     | 31.12.2017 \n",
      " ACCOUNT_RK  | 1972647    \n",
      " CURRENCY_RK | 34         \n",
      " BALANCE_OUT | 5087732.1  \n",
      "-RECORD 4-----------------\n",
      " ON_DATE     | 31.12.2017 \n",
      " ACCOUNT_RK  | 34157174   \n",
      " CURRENCY_RK | 34         \n",
      " BALANCE_OUT | 7097806.9  \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 114\n",
      "Схема:\n",
      "root\n",
      " |-- ON_DATE: string (nullable = true)\n",
      " |-- ACCOUNT_RK: integer (nullable = true)\n",
      " |-- CURRENCY_RK: integer (nullable = true)\n",
      " |-- BALANCE_OUT: double (nullable = true)\n",
      "\n",
      "\n",
      "=== FT_POSTING_F ===\n",
      "-RECORD 0-----------------------\n",
      " OPER_DATE         | 09-01-2018 \n",
      " CREDIT_ACCOUNT_RK | 13630      \n",
      " DEBET_ACCOUNT_RK  | 17436      \n",
      " CREDIT_AMOUNT     | 94333.93   \n",
      " DEBET_AMOUNT      | 18337.76   \n",
      "-RECORD 1-----------------------\n",
      " OPER_DATE         | 09-01-2018 \n",
      " CREDIT_ACCOUNT_RK | 15698716   \n",
      " DEBET_ACCOUNT_RK  | 13630      \n",
      " CREDIT_AMOUNT     | 68294.14   \n",
      " DEBET_AMOUNT      | 31542.06   \n",
      "-RECORD 2-----------------------\n",
      " OPER_DATE         | 09-01-2018 \n",
      " CREDIT_ACCOUNT_RK | 12048338   \n",
      " DEBET_ACCOUNT_RK  | 13630      \n",
      " CREDIT_AMOUNT     | 2192.96    \n",
      " DEBET_AMOUNT      | 98734.33   \n",
      "-RECORD 3-----------------------\n",
      " OPER_DATE         | 09-01-2018 \n",
      " CREDIT_ACCOUNT_RK | 393808409  \n",
      " DEBET_ACCOUNT_RK  | 17244      \n",
      " CREDIT_AMOUNT     | 44179.86   \n",
      " DEBET_AMOUNT      | 98544.65   \n",
      "-RECORD 4-----------------------\n",
      " OPER_DATE         | 09-01-2018 \n",
      " CREDIT_ACCOUNT_RK | 409685020  \n",
      " DEBET_ACCOUNT_RK  | 13630      \n",
      " CREDIT_AMOUNT     | 18843.05   \n",
      " DEBET_AMOUNT      | 889.74     \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 33892\n",
      "Схема:\n",
      "root\n",
      " |-- OPER_DATE: string (nullable = true)\n",
      " |-- CREDIT_ACCOUNT_RK: integer (nullable = true)\n",
      " |-- DEBET_ACCOUNT_RK: integer (nullable = true)\n",
      " |-- CREDIT_AMOUNT: double (nullable = true)\n",
      " |-- DEBET_AMOUNT: double (nullable = true)\n",
      "\n",
      "\n",
      "=== MD_ACCOUNT_D ===\n",
      "-RECORD 0------------------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-01           \n",
      " ACCOUNT_RK           | 36237725             \n",
      " DATA_ACTUAL_END_DATE | 2025-04-21           \n",
      " ACCOUNT_NUMBER       | 30425840700000583001 \n",
      " CHAR_TYPE            | А                    \n",
      " CURRENCY_RK          | 35                   \n",
      " CURRENCY_CODE        | 840                  \n",
      "-RECORD 1------------------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-01           \n",
      " ACCOUNT_RK           | 24656                \n",
      " DATA_ACTUAL_END_DATE | 2025-04-21           \n",
      " ACCOUNT_NUMBER       | 30114840700000770002 \n",
      " CHAR_TYPE            | А                    \n",
      " CURRENCY_RK          | 35                   \n",
      " CURRENCY_CODE        | 840                  \n",
      "-RECORD 2------------------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-01           \n",
      " ACCOUNT_RK           | 18849846             \n",
      " DATA_ACTUAL_END_DATE | 2025-04-21           \n",
      " ACCOUNT_NUMBER       | 30109810500000435003 \n",
      " CHAR_TYPE            | П                    \n",
      " CURRENCY_RK          | 34                   \n",
      " CURRENCY_CODE        | 643                  \n",
      "-RECORD 3------------------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-01           \n",
      " ACCOUNT_RK           | 1972647              \n",
      " DATA_ACTUAL_END_DATE | 2025-04-21           \n",
      " ACCOUNT_NUMBER       | 30111810700000908001 \n",
      " CHAR_TYPE            | П                    \n",
      " CURRENCY_RK          | 34                   \n",
      " CURRENCY_CODE        | 643                  \n",
      "-RECORD 4------------------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-01           \n",
      " ACCOUNT_RK           | 34157174             \n",
      " DATA_ACTUAL_END_DATE | 2025-04-21           \n",
      " ACCOUNT_NUMBER       | 30424810100000583001 \n",
      " CHAR_TYPE            | А                    \n",
      " CURRENCY_RK          | 34                   \n",
      " CURRENCY_CODE        | 643                  \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 224\n",
      "Схема:\n",
      "root\n",
      " |-- DATA_ACTUAL_DATE: date (nullable = true)\n",
      " |-- ACCOUNT_RK: integer (nullable = true)\n",
      " |-- DATA_ACTUAL_END_DATE: date (nullable = true)\n",
      " |-- ACCOUNT_NUMBER: decimal(20,0) (nullable = true)\n",
      " |-- CHAR_TYPE: string (nullable = true)\n",
      " |-- CURRENCY_RK: integer (nullable = true)\n",
      " |-- CURRENCY_CODE: integer (nullable = true)\n",
      "\n",
      "\n",
      "=== MD_CURRENCY_D ===\n",
      "-RECORD 0--------------------------\n",
      " CURRENCY_RK          | 4586704    \n",
      " DATA_ACTUAL_DATE     | 2011-09-06 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_CODE        | 0          \n",
      " CODE_ISO_CHAR        | NON        \n",
      "-RECORD 1--------------------------\n",
      " CURRENCY_RK          | 50         \n",
      " DATA_ACTUAL_DATE     | 2017-05-11 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_CODE        | 356        \n",
      " CODE_ISO_CHAR        | INR        \n",
      "-RECORD 2--------------------------\n",
      " CURRENCY_RK          | 51         \n",
      " DATA_ACTUAL_DATE     | 2017-05-11 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_CODE        | 484        \n",
      " CODE_ISO_CHAR        | MXN        \n",
      "-RECORD 3--------------------------\n",
      " CURRENCY_RK          | 52         \n",
      " DATA_ACTUAL_DATE     | 2017-05-11 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_CODE        | 434        \n",
      " CODE_ISO_CHAR        | LYD        \n",
      "-RECORD 4--------------------------\n",
      " CURRENCY_RK          | 53         \n",
      " DATA_ACTUAL_DATE     | 2017-05-11 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_CODE        | 422        \n",
      " CODE_ISO_CHAR        | LBR        \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 50\n",
      "Схема:\n",
      "root\n",
      " |-- CURRENCY_RK: integer (nullable = true)\n",
      " |-- DATA_ACTUAL_DATE: date (nullable = true)\n",
      " |-- DATA_ACTUAL_END_DATE: date (nullable = true)\n",
      " |-- CURRENCY_CODE: integer (nullable = true)\n",
      " |-- CODE_ISO_CHAR: string (nullable = true)\n",
      "\n",
      "\n",
      "=== MD_EXCHANGE_RATE_D ===\n",
      "-RECORD 0--------------------------\n",
      " DATA_ACTUAL_DATE     | 2016-07-01 \n",
      " DATA_ACTUAL_END_DATE | 2050-12-31 \n",
      " CURRENCY_RK          | 38         \n",
      " REDUCED_COURCE       | 31.8884    \n",
      " CODE_ISO_NUM         | 974        \n",
      "-RECORD 1--------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-31 \n",
      " DATA_ACTUAL_END_DATE | 2018-01-31 \n",
      " CURRENCY_RK          | 427870281  \n",
      " REDUCED_COURCE       | 28.3798    \n",
      " CODE_ISO_NUM         | 933        \n",
      "-RECORD 2--------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-31 \n",
      " DATA_ACTUAL_END_DATE | 2018-01-31 \n",
      " CURRENCY_RK          | 29         \n",
      " REDUCED_COURCE       | 7.11613    \n",
      " CODE_ISO_NUM         | 752        \n",
      "-RECORD 3--------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-31 \n",
      " DATA_ACTUAL_END_DATE | 2018-01-31 \n",
      " CURRENCY_RK          | 529511970  \n",
      " REDUCED_COURCE       | 33.0543    \n",
      " CODE_ISO_NUM         | 944        \n",
      "-RECORD 4--------------------------\n",
      " DATA_ACTUAL_DATE     | 2018-01-31 \n",
      " DATA_ACTUAL_END_DATE | 2018-01-31 \n",
      " CURRENCY_RK          | 62         \n",
      " REDUCED_COURCE       | 8.87555    \n",
      " CODE_ISO_NUM         | 156        \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 892\n",
      "Схема:\n",
      "root\n",
      " |-- DATA_ACTUAL_DATE: date (nullable = true)\n",
      " |-- DATA_ACTUAL_END_DATE: date (nullable = true)\n",
      " |-- CURRENCY_RK: integer (nullable = true)\n",
      " |-- REDUCED_COURCE: double (nullable = true)\n",
      " |-- CODE_ISO_NUM: integer (nullable = true)\n",
      "\n",
      "\n",
      "=== MD_LEDGER_ACCOUNT_S ===\n",
      "-RECORD 0------------------------------------\n",
      " CHAPTER              | А                    \n",
      " CHAPTER_NAME         | Балансовые счета     \n",
      " SECTION_NUMBER       | 3                    \n",
      " SECTION_NAME         | МЕЖБАНКОВСКИЕ ОПЕ... \n",
      " SUBSECTION_NAME      | МЕЖБАНКОВСКИЕ РАС... \n",
      " LEDGER1_ACCOUNT      | 302                  \n",
      " LEDGER1_ACCOUNT_NAME | Счета кредитных о... \n",
      " LEDGER_ACCOUNT       | 30204                \n",
      " LEDGER_ACCOUNT_NAME  | Обязательные резе... \n",
      " CHARACTERISTIC       | А                    \n",
      " START_DATE           | 2014-01-01           \n",
      " END_DATE             | 2050-12-31           \n",
      "-RECORD 1------------------------------------\n",
      " CHAPTER              | А                    \n",
      " CHAPTER_NAME         | Балансовые счета     \n",
      " SECTION_NUMBER       | 3                    \n",
      " SECTION_NAME         | МЕЖБАНКОВСКИЕ ОПЕ... \n",
      " SUBSECTION_NAME      | МЕЖБАНКОВСКИЕ РАС... \n",
      " LEDGER1_ACCOUNT      | 301                  \n",
      " LEDGER1_ACCOUNT_NAME | Корреспондентские... \n",
      " LEDGER_ACCOUNT       | 30109                \n",
      " LEDGER_ACCOUNT_NAME  | Корреспондентские... \n",
      " CHARACTERISTIC       | П                    \n",
      " START_DATE           | 2008-01-01           \n",
      " END_DATE             | 2050-12-31           \n",
      "-RECORD 2------------------------------------\n",
      " CHAPTER              | А                    \n",
      " CHAPTER_NAME         | Балансовые счета     \n",
      " SECTION_NUMBER       | 3                    \n",
      " SECTION_NAME         | МЕЖБАНКОВСКИЕ ОПЕ... \n",
      " SUBSECTION_NAME      | МЕЖБАНКОВСКИЕ РАС... \n",
      " LEDGER1_ACCOUNT      | 301                  \n",
      " LEDGER1_ACCOUNT_NAME | Корреспондентские... \n",
      " LEDGER_ACCOUNT       | 30110                \n",
      " LEDGER_ACCOUNT_NAME  | Корреспондентские... \n",
      " CHARACTERISTIC       | А                    \n",
      " START_DATE           | 2008-01-01           \n",
      " END_DATE             | 2050-12-31           \n",
      "-RECORD 3------------------------------------\n",
      " CHAPTER              | А                    \n",
      " CHAPTER_NAME         | Балансовые счета     \n",
      " SECTION_NUMBER       | 3                    \n",
      " SECTION_NAME         | МЕЖБАНКОВСКИЕ ОПЕ... \n",
      " SUBSECTION_NAME      | МЕЖБАНКОВСКИЕ РАС... \n",
      " LEDGER1_ACCOUNT      | 301                  \n",
      " LEDGER1_ACCOUNT_NAME | Корреспондентские... \n",
      " LEDGER_ACCOUNT       | 30111                \n",
      " LEDGER_ACCOUNT_NAME  | Корреспондентские... \n",
      " CHARACTERISTIC       | П                    \n",
      " START_DATE           | 2008-01-01           \n",
      " END_DATE             | 2050-12-31           \n",
      "-RECORD 4------------------------------------\n",
      " CHAPTER              | А                    \n",
      " CHAPTER_NAME         | Балансовые счета     \n",
      " SECTION_NUMBER       | 3                    \n",
      " SECTION_NAME         | МЕЖБАНКОВСКИЕ ОПЕ... \n",
      " SUBSECTION_NAME      | МЕЖБАНКОВСКИЕ РАС... \n",
      " LEDGER1_ACCOUNT      | 301                  \n",
      " LEDGER1_ACCOUNT_NAME | Корреспондентские... \n",
      " LEDGER_ACCOUNT       | 30126                \n",
      " LEDGER_ACCOUNT_NAME  | Резервы на возмож... \n",
      " CHARACTERISTIC       | П                    \n",
      " START_DATE           | 2008-01-01           \n",
      " END_DATE             | 2050-12-31           \n",
      "only showing top 5 rows\n",
      "\n",
      "Всего строк: 18\n",
      "Схема:\n",
      "root\n",
      " |-- CHAPTER: string (nullable = true)\n",
      " |-- CHAPTER_NAME: string (nullable = true)\n",
      " |-- SECTION_NUMBER: integer (nullable = true)\n",
      " |-- SECTION_NAME: string (nullable = true)\n",
      " |-- SUBSECTION_NAME: string (nullable = true)\n",
      " |-- LEDGER1_ACCOUNT: integer (nullable = true)\n",
      " |-- LEDGER1_ACCOUNT_NAME: string (nullable = true)\n",
      " |-- LEDGER_ACCOUNT: integer (nullable = true)\n",
      " |-- LEDGER_ACCOUNT_NAME: string (nullable = true)\n",
      " |-- CHARACTERISTIC: string (nullable = true)\n",
      " |-- START_DATE: date (nullable = true)\n",
      " |-- END_DATE: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def show_parquet_head(spark, table_paths):\n",
    "    \"\"\"Выводит первые 5 строк каждой Parquet таблицы\"\"\"\n",
    "    for table_name, path in table_paths.items():\n",
    "        try:\n",
    "            print(f\"\\n=== {table_name} ===\")\n",
    "            df = spark.read.parquet(path)\n",
    "            df.show(5, vertical=True)\n",
    "            print(f\"Всего строк: {df.count()}\")\n",
    "            print(\"Схема:\")\n",
    "            df.printSchema()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при чтении таблицы {table_name}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ShowParquetHead\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Пути к Parquet-таблицам\n",
    "    table_paths = {\n",
    "        \"FT_BALANCE_F\": \"data/parquet/FT_BALANCE_F\",\n",
    "        \"FT_POSTING_F\": \"data/parquet/FT_POSTING_F\",\n",
    "        \"MD_ACCOUNT_D\": \"data/parquet/MD_ACCOUNT_D\",\n",
    "        \"MD_CURRENCY_D\": \"data/parquet/MD_CURRENCY_D\",\n",
    "        \"MD_EXCHANGE_RATE_D\": \"data/parquet/MD_EXCHANGE_RATE_D\",\n",
    "        \"MD_LEDGER_ACCOUNT_S\": \"data/parquet/MD_LEDGER_ACCOUNT_S\"\n",
    "    }\n",
    "\n",
    "    show_parquet_head(spark, table_paths)\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
